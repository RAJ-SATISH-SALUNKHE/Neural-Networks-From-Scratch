{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader:\n",
    "    def __init__(self, train_images_path, train_labels_path, test_images_path, test_labels_path):\n",
    "        self.train_images_path = train_images_path\n",
    "        self.train_labels_path = train_labels_path\n",
    "        self.test_images_path = test_images_path\n",
    "        self.test_labels_path = test_labels_path\n",
    "\n",
    "    def load_images(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Skip the magic number and dimensions (first 16 bytes)\n",
    "            f.read(16)\n",
    "            # Read the remaining bytes and reshape into a 28x28 array\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            return data.reshape(-1, 28, 28).astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    def load_labels(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Skip the magic number (first 8 bytes)\n",
    "            f.read(8)\n",
    "            # Read the remaining bytes as labels\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "    def load_data(self):\n",
    "        train_images = self.load_images(self.train_images_path)\n",
    "        train_labels = self.load_labels(self.train_labels_path)\n",
    "        test_images = self.load_images(self.test_images_path)\n",
    "        test_labels = self.load_labels(self.test_labels_path)\n",
    "\n",
    "        # Flatten images to 1D\n",
    "        # train_images = np.reshape(train_images, (train_images.shape[0], -1))\n",
    "        # test_images = np.reshape(test_images, (test_images.shape[0], -1))\n",
    "\n",
    "        return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loader = MNISTLoader(\n",
    "    train_images_path='C:\\\\Users\\\\Raj.Salunkhe\\\\Desktop\\\\nn from scratch\\\\train-images.idx3-ubyte',\n",
    "    train_labels_path='C:\\\\Users\\\\Raj.Salunkhe\\\\Desktop\\\\nn from scratch\\\\train-labels.idx1-ubyte',\n",
    "    test_images_path='C:\\\\Users\\\\Raj.Salunkhe\\\\Desktop\\\\nn from scratch\\\\t10k-images.idx3-ubyte',\n",
    "    test_labels_path='C:\\\\Users\\\\Raj.Salunkhe\\\\Desktop\\\\nn from scratch\\\\t10k-labels.idx1-ubyte'\n",
    ")\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = mnist_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.from_numpy(train_images).clone()\n",
    "train_labels_tensor = torch.from_numpy(train_labels).clone()\n",
    "test_images_tensor = torch.from_numpy(test_images).clone()\n",
    "test_labels_tensor = torch.from_numpy(test_labels).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1, pool_size=2, pool_stride=2, lr = 0.001, apply_padding = True, apply_pooling = False):\n",
    "        \"\"\"\n",
    "        Initialize a Conv2D layer.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int or tuple): Size of the convolution kernel (filter).\n",
    "            stride (int): Stride of the convolution.\n",
    "            padding (int): Amount of zero-padding around the input.\n",
    "        \"\"\"\n",
    "        super(Conv2D, self).__init__()  # Initialize the parent class (nn.Module)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_stride = pool_stride\n",
    "        self.learning_rate = lr\n",
    "        self.apply_padding = apply_padding\n",
    "        self.apply_pooling = apply_pooling\n",
    "        \n",
    "        \n",
    "        # Initialize weights and biases using nn.Parameter to track gradients\n",
    "        self.weights = torch.randn(out_channels, in_channels, *self.kernel_size, requires_grad=True) * 0.01\n",
    "        self.biases = torch.zeros(out_channels, 1, requires_grad=True)\n",
    "\n",
    "        self.params = [list(torch.flatten(self.weights))].extend(list(torch.flatten(self.biases)))\n",
    "\n",
    "    def add_padding(self, input_matrices: torch.tensor):\n",
    "        batch_size, in_channels, height, width = input_matrices.shape\n",
    "\n",
    "        padded_matrices = torch.zeros(batch_size, in_channels, height + 2 * self.padding, width + 2 * self.padding)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for c in range(in_channels):\n",
    "                input_matrix = input_matrices[b, c]\n",
    "                \n",
    "                horizontal_pads = torch.zeros(height, self.padding, requires_grad=True)\n",
    "                vertical_pads = torch.zeros(self.padding, width + 2 * self.padding, requires_grad=True)\n",
    "\n",
    "                padded_matrix = torch.cat((horizontal_pads, input_matrix), dim=1)  \n",
    "                padded_matrix = torch.cat((padded_matrix, horizontal_pads), dim=1)\n",
    "\n",
    "                padded_matrix = torch.cat((vertical_pads, padded_matrix), dim=0)  \n",
    "                padded_matrix = torch.cat((padded_matrix, vertical_pads), dim=0)\n",
    "\n",
    "                padded_matrices[b, c] = padded_matrix\n",
    "\n",
    "        return padded_matrices\n",
    "    \n",
    "    \n",
    "    def forward(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Key Assumptions:\n",
    "        1. Input, filters are square\n",
    "        2. Stride and padding is one dimensional\n",
    "        \"\"\"\n",
    "        B, C, H, W = input_matrix.shape\n",
    "        if self.apply_padding:\n",
    "            input_matrix = self.add_padding(input_matrix)\n",
    "\n",
    "        if self.apply_pooling:\n",
    "            output = self.pooling(input_matrix ,  pool_type='max')\n",
    "            return output\n",
    "\n",
    "        # Extracting the dimensions out of the input matrix\n",
    "        kernel_height, kernel_width = self.kernel_size\n",
    "        stride = self.stride\n",
    "        padding = self.padding\n",
    "\n",
    "        OH = round(((W + 2*padding - kernel_height)/stride)) + 1\n",
    "        OW = round(((W + 2*padding - kernel_width)/stride)) + 1\n",
    "\n",
    "\n",
    "        output = torch.zeros(B, self.out_channels, OH, OW)\n",
    "\n",
    "        for i in range(OH):\n",
    "            for j in range(OW):\n",
    "                height_start = i * stride\n",
    "                width_start = j * stride\n",
    "\n",
    "                height_end = height_start + kernel_height\n",
    "                width_end = width_start + kernel_width\n",
    "\n",
    "                input_region = input_matrix[:, :, height_start:height_end, width_start:width_end]\n",
    "\n",
    "                for k in range(self.out_channels):\n",
    "                    output[:, k, i, j] = torch.sum(input_region * self.weights[k], dim=(1, 2, 3)) + self.biases[k]\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def pooling(self, input_matrix, pool_type='max'):\n",
    "        B, C, H, W = input_matrix.shape\n",
    "\n",
    "        OH = (H - self.pool_size) // self.pool_stride + 1\n",
    "        OW = (W - self.pool_size) // self.pool_stride + 1\n",
    "\n",
    "        output = torch.zeros(B, C, OH, OW)\n",
    "\n",
    "        for b in range(B):\n",
    "            for c in range(C):\n",
    "                for i in range(OH):\n",
    "                    for j in range(OW):\n",
    "                        height_start = i * self.pool_stride\n",
    "                        width_start = j * self.pool_stride\n",
    "\n",
    "                        height_end = height_start + self.pool_size\n",
    "                        width_end = width_start + self.pool_size\n",
    "\n",
    "                        input_region = input_matrix[b, c, height_start:height_end, width_start:width_end]\n",
    "\n",
    "                        if pool_type == 'max':\n",
    "                            # Max pooling\n",
    "                            output[b, c, i, j] = torch.max(input_region)\n",
    "                        elif pool_type == 'average':\n",
    "                            # Average pooling\n",
    "                            output[b, c, i, j] = torch.mean(input_region)\n",
    "                        else:\n",
    "                            raise ValueError(f\"Unsupported pool_type: {pool_type}\")\n",
    "\n",
    "        return output\n",
    "\n",
    "    def mse_loss(self, output, target):\n",
    "        \"\"\"Mean Squared Error Loss\"\"\"\n",
    "        return torch.mean((output - target) ** 2)\n",
    "\n",
    "    def backward(self, loss):\n",
    "        \"\"\"\n",
    "        Backward pass to compute the gradients using autograd.\n",
    "        Args:\n",
    "            loss: The computed loss value (scalar).\n",
    "        \"\"\"\n",
    "        # Perform backpropagation to compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "    def update_weights(self):\n",
    "        \"\"\"\n",
    "        Update the weights using gradient descent (or any optimizer).\n",
    "        Here, we are doing simple gradient descent.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  \n",
    "            self.weights -= self.learning_rate * self.weights.grad\n",
    "            self.biases -= self.learning_rate * self.biases.grad\n",
    "\n",
    "            self.weights.grad.zero_()\n",
    "            self.biases.grad.zero_()\n",
    "        \n",
    "\n",
    "conv = Conv2D(in_channels=3, out_channels=1, kernel_size=3)\n",
    "input_matrix = torch.randn(1, 3, 10, 10)\n",
    "output = conv.forward(input_matrix)\n",
    "pooled_op = conv.pooling(output)\n",
    "\n",
    "output.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = [\n",
    "    Conv2D(in_channels=1, out_channels=3, kernel_size=3, apply_padding=True),\n",
    "    Conv2D(in_channels=3, out_channels=2, kernel_size=3, apply_padding=False),\n",
    "    Conv2D(in_channels=2, out_channels=1, kernel_size=3, apply_pooling=True)\n",
    "\n",
    "]\n",
    "\n",
    "model_params = []\n",
    "for layer in model_layers:\n",
    "    # model_params.extend(layer.params)\n",
    "    model_params.extend(list(torch.flatten(layer.weights)))\n",
    "    model_params.extend(list(torch.flatten(layer.biases)))\n",
    "\n",
    "\n",
    "initial_input = None\n",
    "target = None\n",
    "final_layer_weights = torch.randn(100, 10, requires_grad=True)\n",
    "final_layer_biases = torch.randn(10, requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "def forward(initial_input, target, final_layer_weights, final_layer_biases):\n",
    "    output = initial_input\n",
    "    for layer in model_layers:\n",
    "        output = layer.forward(output)\n",
    "    \n",
    "    # Flatten properly\n",
    "    flattened_layer = output.view(output.shape[0], -1)\n",
    "\n",
    "    # Fully connected layer\n",
    "    output = flattened_layer @ final_layer_weights + final_layer_biases\n",
    "\n",
    "    # Mean Squared Error loss\n",
    "    loss = torch.mean((output - target) ** 2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, targets, lr = 0.01, iters = 100):\n",
    "    for i in range(iters):\n",
    "        loss = forward(inputs, targets, final_layer_weights, final_layer_biases)\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        for param in model_params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()\n",
    "\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_labels)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m----> 8\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m train(inputs , targets)\n",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(inputs, targets, lr, iters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(inputs, targets, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[1;32m----> 3\u001b[0m         loss \u001b[38;5;241m=\u001b[39m forward(inputs, targets, final_layer_weights, final_layer_biases)\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m      5\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[44], line 25\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(initial_input, target, final_layer_weights, final_layer_biases)\u001b[0m\n\u001b[0;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m initial_input\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model_layers:\n\u001b[1;32m---> 25\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Flatten properly\u001b[39;00m\n\u001b[0;32m     28\u001b[0m flattened_layer \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[40], line 61\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[1;34m(self, input_matrix)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_matrix):\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Key Assumptions:\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    1. Input, filters are square\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    2. Stride and padding is one dimensional\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     B, C, H, W \u001b[38;5;241m=\u001b[39m input_matrix\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_padding:\n\u001b[0;32m     63\u001b[0m         input_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_padding(input_matrix)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "inputs = train_images_tensor\n",
    "targets = torch.from_numpy(train_labels).clone().float()\n",
    "\n",
    "loss = math.inf\n",
    "\n",
    "final_loss = train(inputs , targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2905924320220947\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_weights()\n",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m, in \u001b[0;36mCNN.update_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mbiases \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mbiases\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Manually update fully connected layers\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Users\\Raj.Salunkhe\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'learning_rate'"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1, 28, 28)  # Batch of 32 grayscale images (28x28)\n",
    "labels = torch.randint(0, 10, (1,))  # Random labels\n",
    "\n",
    "# Forward pass\n",
    "outputs = model.forward(inputs)\n",
    "\n",
    "# Compute loss and backward pass\n",
    "loss = model.backward(outputs, labels)\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# Update weights\n",
    "model.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
